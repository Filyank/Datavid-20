{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos los datos que usaremos para entrenar nuestro algorítmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv',usecols = ['text','target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primer vistazo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "0     Our Deeds are the Reason of this #earthquake M...       1\n",
       "1                Forest fire near La Ronge Sask. Canada       1\n",
       "2     All residents asked to 'shelter in place' are ...       1\n",
       "3     13,000 people receive #wildfires evacuation or...       1\n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1\n",
       "...                                                 ...     ...\n",
       "7608  Two giant cranes holding a bridge collapse int...       1\n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1\n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1\n",
       "7611  Police investigating after an e-bike collided ...       1\n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1\n",
       "\n",
       "[7613 rows x 2 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos una limpieza del texto que se corresponde a los tweets para obtener un mejor resultado a la hora de procesar los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definicion de funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminar numeros de un texto\n",
    "def eliminar_numeros(text):\n",
    "    return re.sub(\"\\d+\", \"\",text)\n",
    "\n",
    "#Eliminar puntuacion\n",
    "def eliminar_puntuacion(text):\n",
    "    return re.sub(r'[^\\w\\s]','',text)\n",
    "\n",
    "#Pasar letras a minusculas\n",
    "def minusculas(text):\n",
    "    return text.lower()\n",
    "\n",
    "#Eliminar caracteres especiales\n",
    "def eliminar_caracteres(text):\n",
    "    return re.sub('[^a-zA-Z0-9 \\n\\.]', '',text)\n",
    "\n",
    "#Eliminar urls\n",
    "def eliminar_url(text):\n",
    "    url_reg = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_reg.sub(r'',text)\n",
    "\n",
    "#Eliminar palabras comunes como articulos,pronombres,preposiciones\n",
    "def eliminar_comunes(text):\n",
    "    comunes = stopwords.words('english')\n",
    "    newtext = ''\n",
    "    for word in text.split():\n",
    "        if word not in comunes:\n",
    "            newtext += ' ' + word\n",
    "    return newtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicamos las funciones a nuestros datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(eliminar_numeros)\n",
    "data['text'] = data['text'].apply(eliminar_puntuacion)\n",
    "data['text'] = data['text'].apply(minusculas)\n",
    "data['text'] = data['text'].apply(eliminar_caracteres)\n",
    "data['text'] = data['text'].apply(eliminar_url)\n",
    "data['text'] = data['text'].apply(eliminar_comunes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>residents asked shelter place notified office...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people receive wildfires evacuation orders ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>got sent photo ruby alaska smoke wildfires po...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>two giant cranes holding bridge collapse near...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>ariaahrary thetawniest control wild fires cal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>utckm volcano hawaii httptcozdtoydebj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>police investigating ebike collided car littl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>latest homes razed northern california wildfi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "0          deeds reason earthquake may allah forgive us       1\n",
       "1                 forest fire near la ronge sask canada       1\n",
       "2      residents asked shelter place notified office...       1\n",
       "3      people receive wildfires evacuation orders ca...       1\n",
       "4      got sent photo ruby alaska smoke wildfires po...       1\n",
       "...                                                 ...     ...\n",
       "7608   two giant cranes holding bridge collapse near...       1\n",
       "7609   ariaahrary thetawniest control wild fires cal...       1\n",
       "7610              utckm volcano hawaii httptcozdtoydebj       1\n",
       "7611   police investigating ebike collided car littl...       1\n",
       "7612   latest homes razed northern california wildfi...       1\n",
       "\n",
       "[7613 rows x 2 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representando el texto de los tweets como una matriz de datos numéricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llamaremos token a las palabras que conforman el texto de los tweets. Podemos entonces crear una matriz cuyas columnas sean los tokens que aparecen en todos los tweets y las filas cada uno de los tweets. Sean aij los elementos de la matriz. El elemento aij representa la cantidad de veces que aparece el token j en el tweet i."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomemos tres tweets cualesquiera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplo = ['hola mi nombre mi federico', 'me gusta mi nombre', 'mi nombre nombre es federico']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(analyzer='word',binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['es', 'federico', 'gusta', 'hola', 'me', 'mi', 'nombre']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x7 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 12 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ejemplo_dtm = vect.transform(ejemplo)\n",
    "ejemplo_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplo_array = ejemplo_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>es</th>\n",
       "      <th>federico</th>\n",
       "      <th>gusta</th>\n",
       "      <th>hola</th>\n",
       "      <th>me</th>\n",
       "      <th>mi</th>\n",
       "      <th>nombre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   es  federico  gusta  hola  me  mi  nombre\n",
       "0   0         1      0     1   0   2       1\n",
       "1   0         0      1     0   1   1       1\n",
       "2   1         1      0     0   0   1       2"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ejemplo_array,columns = vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como la mayoría de los tweets utilizan un conjunto reducido de tokens con respecto al total de tokens con el que trabajaremos, se espera que la mayoría de los elementos de la matriz sean cero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Armando la matriz para nuestros datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particionando los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particionamos nuestros datos en dos ya que una parte de ellos será utilizada para entrenar a nuestro algorítmo y la otra será utilizada para probarlo. En nuestro caso las variables X respresentan a el texto de los tweets e Y el target asociado a los tweets. La intención de nuestro algorítmo es dado un determinado texto de un tweet(x) poder predecir su target(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "Y = data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test= train_test_split(data.text, data.target, test_size=0.013,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7514"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciando el vectorizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(analyzer='word',binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenemos una lista con todos los tokens obtenidos de los tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaaa',\n",
       " 'aaaaaaallll',\n",
       " 'aaaaaand',\n",
       " 'aaarrrgghhh',\n",
       " 'aaceorg',\n",
       " 'aal',\n",
       " 'aampb',\n",
       " 'aampw',\n",
       " 'aan',\n",
       " 'aannnnd',\n",
       " 'aar',\n",
       " 'aaronthefm',\n",
       " 'aashiqui',\n",
       " 'ab',\n",
       " 'aba',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandonedpics',\n",
       " 'abandoning',\n",
       " 'abbandoned',\n",
       " 'abbott',\n",
       " 'abbruchsimulator',\n",
       " 'abbswinston',\n",
       " 'abbyairshow',\n",
       " 'abc',\n",
       " 'abcchicago',\n",
       " 'abceyewitness',\n",
       " 'abcnews',\n",
       " 'abcnorio',\n",
       " 'abcs',\n",
       " 'abe',\n",
       " 'aberdeen',\n",
       " 'aberdeenfanpage',\n",
       " 'aberdeenfc',\n",
       " 'aberystwythshrewsbury',\n",
       " 'abes',\n",
       " 'abha',\n",
       " 'abia',\n",
       " 'ability',\n",
       " 'abject',\n",
       " 'ablaze',\n",
       " 'able',\n",
       " 'ableg',\n",
       " 'abninfvet',\n",
       " 'aboard',\n",
       " 'abomb',\n",
       " 'abombed',\n",
       " 'abomination',\n",
       " 'abortion',\n",
       " 'abortions',\n",
       " 'abouts',\n",
       " 'abrancaballero',\n",
       " 'abs',\n",
       " 'absence',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutsumya',\n",
       " 'abstorm',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'absurdly',\n",
       " 'abubaraa',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuseddesolateamplost',\n",
       " 'abuses',\n",
       " 'abusing',\n",
       " 'abysmaljoiner',\n",
       " 'ac',\n",
       " 'acaciapenn',\n",
       " 'academia',\n",
       " 'acarewornheart',\n",
       " 'acc',\n",
       " 'accept',\n",
       " 'accepte',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accidentalprophecy',\n",
       " 'accidently',\n",
       " 'accidents',\n",
       " 'accidentwho',\n",
       " 'accionempresa',\n",
       " 'accompanying',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accountable',\n",
       " 'accounts',\n",
       " 'accuracy',\n",
       " 'accused',\n",
       " 'accuses',\n",
       " 'accustomed',\n",
       " 'acdcd',\n",
       " 'acdelco',\n",
       " 'ace',\n",
       " 'acebabes',\n",
       " 'acebreakingnews',\n",
       " 'acee',\n",
       " 'acenewsdesk',\n",
       " 'acesse',\n",
       " 'achedin',\n",
       " 'achieve',\n",
       " 'achievement',\n",
       " 'achieving',\n",
       " 'achimota',\n",
       " 'aching',\n",
       " 'acid',\n",
       " 'acids',\n",
       " 'acmilan',\n",
       " 'acne',\n",
       " 'acoustic',\n",
       " 'acousticmaloley',\n",
       " 'acquiesce',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquisitions',\n",
       " 'acres',\n",
       " 'acronym',\n",
       " 'across',\n",
       " 'acrylic',\n",
       " 'act',\n",
       " 'actavis',\n",
       " 'acted',\n",
       " 'actin',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actionmoviestaughtus',\n",
       " 'actions',\n",
       " 'activate',\n",
       " 'activated',\n",
       " 'activates',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activision',\n",
       " 'activist',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actress',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'acura',\n",
       " 'acute',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adamantly',\n",
       " 'adamnibloe',\n",
       " 'adamrubinespn',\n",
       " 'adamtuss',\n",
       " 'adani',\n",
       " 'adanne',\n",
       " 'adaptation',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addict',\n",
       " 'addiction',\n",
       " 'addicts',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'address',\n",
       " 'addresses',\n",
       " 'addtexastonextdtour',\n",
       " 'adelaide',\n",
       " 'adhd',\n",
       " 'adidas',\n",
       " 'adiossuperbacterias',\n",
       " 'adjust',\n",
       " 'adjustable',\n",
       " 'adjuster',\n",
       " 'admin',\n",
       " 'administration',\n",
       " 'administrative',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'adndotcom',\n",
       " 'adopt',\n",
       " 'adoption',\n",
       " 'adoptive',\n",
       " 'adorable',\n",
       " 'adorableappple',\n",
       " 'adrianpeel',\n",
       " 'adriasimon',\n",
       " 'adriennetomah',\n",
       " 'ads',\n",
       " 'adsit',\n",
       " 'adult',\n",
       " 'adultblackmale',\n",
       " 'adults',\n",
       " 'adumbbb',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advances',\n",
       " 'advantages',\n",
       " 'adventures',\n",
       " 'adverse',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advice',\n",
       " 'advised',\n",
       " 'advisory',\n",
       " 'adweek',\n",
       " 'aeg',\n",
       " 'aelinrhee',\n",
       " 'aeroplane',\n",
       " 'aerospace',\n",
       " 'aesop',\n",
       " 'aesthetic',\n",
       " 'af',\n",
       " 'afc',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affects',\n",
       " 'affiliate',\n",
       " 'affiliation',\n",
       " 'afflecki',\n",
       " 'affliction',\n",
       " 'afghan',\n",
       " 'afghanistan',\n",
       " 'afghetcleft',\n",
       " 'afk',\n",
       " 'afloat',\n",
       " 'afp',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'africanbaze',\n",
       " 'africans',\n",
       " 'africansinsf',\n",
       " 'africas',\n",
       " 'afrikaan',\n",
       " 'afrin',\n",
       " 'afte',\n",
       " 'afterhaiyan',\n",
       " 'afterhours',\n",
       " 'afterlife',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'aftershock',\n",
       " 'aftershockdelo',\n",
       " 'aftershockorg',\n",
       " 'aftershocks',\n",
       " 'afterwards',\n",
       " 'afycso',\n",
       " 'ag',\n",
       " 'agdq',\n",
       " 'age',\n",
       " 'ageekyfangirl',\n",
       " 'agencies',\n",
       " 'agency',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'aggarwal',\n",
       " 'aggressif',\n",
       " 'aggression',\n",
       " 'aggressive',\n",
       " 'aggressively',\n",
       " 'agnivesh',\n",
       " 'agnus',\n",
       " 'ago',\n",
       " 'agochicago',\n",
       " 'agony',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreements',\n",
       " 'agrees',\n",
       " 'agreeshe',\n",
       " 'agthanover',\n",
       " 'agtparis',\n",
       " 'aguero',\n",
       " 'agusa',\n",
       " 'agw',\n",
       " 'ah',\n",
       " 'ahahahga',\n",
       " 'ahamedis',\n",
       " 'ahead',\n",
       " 'ahh',\n",
       " 'ahhhh',\n",
       " 'ahhhhh',\n",
       " 'ahhtheenikki',\n",
       " 'ahmazing',\n",
       " 'ahrar',\n",
       " 'ahuh',\n",
       " 'ai',\n",
       " 'aias',\n",
       " 'aid',\n",
       " 'aidade',\n",
       " 'aidan',\n",
       " 'aids',\n",
       " 'aiginsurance',\n",
       " 'aiiamericangiri',\n",
       " 'aiii',\n",
       " 'aim',\n",
       " 'aimlessly',\n",
       " 'aint',\n",
       " 'aintsheperty',\n",
       " 'air',\n",
       " 'airasia',\n",
       " 'airbullet',\n",
       " 'aircraft',\n",
       " 'airhead',\n",
       " 'airhorns',\n",
       " 'airing',\n",
       " 'airlift',\n",
       " 'airlines',\n",
       " 'airplane',\n",
       " 'airplanes',\n",
       " 'airport',\n",
       " 'airports',\n",
       " 'airstrikes',\n",
       " 'airwaves',\n",
       " 'aisle',\n",
       " 'aisumage',\n",
       " 'aitchkaycee',\n",
       " 'ajabrown',\n",
       " 'ajw',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'akame',\n",
       " 'akarb',\n",
       " 'akcsl',\n",
       " 'akgovbillwalker',\n",
       " 'akilah',\n",
       " 'akito',\n",
       " 'akrams',\n",
       " 'aks',\n",
       " 'akumareisu',\n",
       " 'akwa',\n",
       " 'akx',\n",
       " 'akxbskdn',\n",
       " 'al',\n",
       " 'alabama',\n",
       " 'alabamaquake',\n",
       " 'aladdin',\n",
       " 'alameda',\n",
       " 'alamodc',\n",
       " 'alanhahn',\n",
       " 'alarm',\n",
       " 'alarmed',\n",
       " 'alarmems',\n",
       " 'alarming',\n",
       " 'alarmingly',\n",
       " 'alarms',\n",
       " 'alas',\n",
       " 'alaska',\n",
       " 'alaskan',\n",
       " 'alaskas',\n",
       " 'alaskaseafood',\n",
       " 'alba',\n",
       " 'albany',\n",
       " 'albeit',\n",
       " 'alberta',\n",
       " 'albertans',\n",
       " 'albertas',\n",
       " 'albertsons',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'alchemist',\n",
       " 'alcohol',\n",
       " 'alcoholandmetal',\n",
       " 'aldridge',\n",
       " 'alec',\n",
       " 'aleisstokes',\n",
       " 'alekalicante',\n",
       " 'alert',\n",
       " 'alerts',\n",
       " 'alex',\n",
       " 'alexalltimelow',\n",
       " 'alexandrapullin',\n",
       " 'alexandrian',\n",
       " 'alexbelloli',\n",
       " 'alexeivolkov',\n",
       " 'alexhammerstone',\n",
       " 'alexis',\n",
       " 'alexissanchez',\n",
       " 'alexjacobsonpfs',\n",
       " 'alextucker',\n",
       " 'alfapedia',\n",
       " 'algae',\n",
       " 'algeria',\n",
       " 'alhaji',\n",
       " 'alhanda',\n",
       " 'ali',\n",
       " 'alice',\n",
       " 'alien',\n",
       " 'aliens',\n",
       " 'alifaditha',\n",
       " 'align',\n",
       " 'alil',\n",
       " 'alipaper',\n",
       " 'alisonannyoung',\n",
       " 'alive',\n",
       " 'aliveafter',\n",
       " 'allah',\n",
       " 'allahsfinest',\n",
       " 'allay',\n",
       " 'alldaycumshots',\n",
       " 'allegations',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'allegiance',\n",
       " 'allenenbot',\n",
       " 'allergic',\n",
       " 'alley',\n",
       " 'alliance',\n",
       " 'allied',\n",
       " 'allies',\n",
       " 'allin',\n",
       " 'allinwithchris',\n",
       " 'alllivesmatter',\n",
       " 'alllll',\n",
       " 'allocating',\n",
       " 'alloosh',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'alloy',\n",
       " 'allpro',\n",
       " 'allthekidneybeansandsorbetmisha',\n",
       " 'allthenews',\n",
       " 'alltime',\n",
       " 'ally',\n",
       " 'allyinwondrland',\n",
       " 'almighty',\n",
       " 'almost',\n",
       " 'almusafirah',\n",
       " 'alois',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alot',\n",
       " 'alpha',\n",
       " 'alphen',\n",
       " 'alps',\n",
       " 'alrasyiditurasya',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'alrightbut',\n",
       " 'alrighty',\n",
       " 'alska',\n",
       " 'also',\n",
       " 'alsowhat',\n",
       " 'alt',\n",
       " 'altamonte',\n",
       " 'alternate',\n",
       " 'alternative',\n",
       " 'alternatives',\n",
       " 'although',\n",
       " 'alton',\n",
       " 'aluminum',\n",
       " 'alves',\n",
       " 'alvinnelson',\n",
       " 'always',\n",
       " 'alwsl',\n",
       " 'alwx',\n",
       " 'ama',\n",
       " 'amageddon',\n",
       " 'amalie',\n",
       " 'amaramin',\n",
       " 'amateur',\n",
       " 'amateurnester',\n",
       " 'amazed',\n",
       " 'amazin',\n",
       " 'amazing',\n",
       " 'amazingness',\n",
       " 'amazon',\n",
       " 'amazondeals',\n",
       " 'amazons',\n",
       " 'amber',\n",
       " 'ambition',\n",
       " 'ambleside',\n",
       " 'ambulance',\n",
       " 'ambulances',\n",
       " 'ambulancewe',\n",
       " 'amcx',\n",
       " 'amdollela',\n",
       " 'ameenshaikh',\n",
       " 'amen',\n",
       " 'amends',\n",
       " 'ameribag',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americanlegion',\n",
       " 'americans',\n",
       " 'americas',\n",
       " 'ames',\n",
       " 'amicos',\n",
       " 'amicospizzato',\n",
       " 'amid',\n",
       " 'amiddleaged',\n",
       " 'amiibos',\n",
       " 'aminakh',\n",
       " 'aminespn',\n",
       " 'amino',\n",
       " 'amirite',\n",
       " 'amirkingkhan',\n",
       " 'amo',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amp',\n",
       " 'ampamp',\n",
       " 'ampask',\n",
       " 'ampgot',\n",
       " 'amplifier',\n",
       " 'ampmdash',\n",
       " 'ampmillions',\n",
       " 'ampmonsteramp',\n",
       " 'ampor',\n",
       " 'ampstart',\n",
       " 'ampstory',\n",
       " 'ampwanted',\n",
       " 'amreading',\n",
       " 'amritsar',\n",
       " 'amsal',\n",
       " 'amsosorry',\n",
       " 'amssummer',\n",
       " 'amsterdam',\n",
       " 'amumumux',\n",
       " 'amznfavorites',\n",
       " 'ana',\n",
       " 'anakin',\n",
       " 'analog',\n",
       " 'analysis',\n",
       " 'anarchicteapot',\n",
       " 'anarchy',\n",
       " 'anathemazhiv',\n",
       " 'anatomy',\n",
       " 'anchor',\n",
       " 'anchorage',\n",
       " 'anchors',\n",
       " 'ancient',\n",
       " 'ancop',\n",
       " 'andchina',\n",
       " 'anders',\n",
       " 'anderson',\n",
       " 'andor',\n",
       " 'andre',\n",
       " 'andrea',\n",
       " 'andrew',\n",
       " 'android',\n",
       " 'androidgames',\n",
       " 'ands',\n",
       " 'andy',\n",
       " 'andygilder',\n",
       " 'anellatulip',\n",
       " 'anew',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angeles',\n",
       " 'angelheartnight',\n",
       " 'angelina',\n",
       " 'angelriveralib',\n",
       " 'angels',\n",
       " 'angelstar',\n",
       " 'anger',\n",
       " 'angers',\n",
       " 'angharadjames',\n",
       " 'angioplasty',\n",
       " 'angry',\n",
       " 'angusmacneilsnp',\n",
       " 'anhqdc',\n",
       " 'ani',\n",
       " 'animal',\n",
       " 'animaladvocate',\n",
       " 'animallogic',\n",
       " 'animalrescue',\n",
       " 'animals',\n",
       " 'animations',\n",
       " 'animatronics',\n",
       " 'anime',\n",
       " 'aniston',\n",
       " 'anjem',\n",
       " 'ankle',\n",
       " 'ankles',\n",
       " 'anna',\n",
       " 'annaciclismo',\n",
       " 'annajhm',\n",
       " 'annddd',\n",
       " 'annealiz',\n",
       " 'annihilate',\n",
       " 'annihilated',\n",
       " 'annihilating',\n",
       " 'annihilation',\n",
       " 'anniversary',\n",
       " 'annmarieronan',\n",
       " 'annonymous',\n",
       " 'annoucement',\n",
       " 'announce',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'announces',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annual',\n",
       " 'anonchimp',\n",
       " 'anonymous',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answers',\n",
       " 'ant',\n",
       " 'ante',\n",
       " 'anthelmintic',\n",
       " 'anthology',\n",
       " 'anthony',\n",
       " 'anthonys',\n",
       " 'anthrax',\n",
       " 'anthxvy',\n",
       " 'anti',\n",
       " 'antiblight',\n",
       " 'antichrist',\n",
       " 'antifeminist',\n",
       " 'antioch',\n",
       " 'antiochhickoryhollowtn',\n",
       " 'antiochus',\n",
       " 'antiterrorism',\n",
       " 'antonio',\n",
       " 'antony',\n",
       " 'antpips',\n",
       " 'ants',\n",
       " 'anu',\n",
       " 'anxiety',\n",
       " 'anxietyproblems',\n",
       " 'anxious',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'anza',\n",
       " 'aogashima',\n",
       " 'aoms',\n",
       " 'ap',\n",
       " 'apano',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apartments',\n",
       " 'apaz',\n",
       " 'apc',\n",
       " 'apch',\n",
       " 'apcpdp',\n",
       " 'apd',\n",
       " 'apga',\n",
       " 'aphiabeta',\n",
       " 'aphl',\n",
       " 'aphyr',\n",
       " 'apiece',\n",
       " 'apocalpytic',\n",
       " 'apocalypse',\n",
       " 'apocalyptic',\n",
       " 'apollo',\n",
       " 'apollobrown',\n",
       " 'apollobrowns',\n",
       " 'apologies',\n",
       " 'apologise',\n",
       " 'apologized',\n",
       " 'app',\n",
       " 'appalling',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeals',\n",
       " 'appeared',\n",
       " 'appears',\n",
       " 'appease',\n",
       " 'apperception',\n",
       " 'appetite',\n",
       " 'applaud',\n",
       " 'apple',\n",
       " 'appleofficlal',\n",
       " 'applications',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'appointment',\n",
       " 'appoints',\n",
       " 'appraisal',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciativeinquiry',\n",
       " 'approach',\n",
       " 'approaches',\n",
       " 'approaching',\n",
       " 'appropriate',\n",
       " 'appropriation',\n",
       " 'approval',\n",
       " 'approves',\n",
       " 'appx',\n",
       " 'appys',\n",
       " 'apr',\n",
       " 'april',\n",
       " 'apropos',\n",
       " 'apt',\n",
       " 'aptlyengineerd',\n",
       " 'apts',\n",
       " 'apunk',\n",
       " 'aquahttptcoscghlpiq',\n",
       " 'aquarium',\n",
       " 'aquarius',\n",
       " 'ar',\n",
       " 'ara',\n",
       " 'arab',\n",
       " 'arabia',\n",
       " 'arabian',\n",
       " 'arabic',\n",
       " 'arachys',\n",
       " 'arcade',\n",
       " 'arceen',\n",
       " 'archetype',\n",
       " 'archipelagowolves',\n",
       " 'architect',\n",
       " 'architects',\n",
       " 'architecture',\n",
       " 'area',\n",
       " 'areal',\n",
       " 'areas',\n",
       " 'areasminor',\n",
       " 'areavoluntaryinciwebmad',\n",
       " 'aredeluged',\n",
       " 'arena',\n",
       " 'arenanone',\n",
       " 'arent',\n",
       " 'areva',\n",
       " 'arfur',\n",
       " 'argentaelite',\n",
       " 'argentina',\n",
       " 'argentinean',\n",
       " 'argentings',\n",
       " 'argh',\n",
       " 'argsuppose',\n",
       " 'argue',\n",
       " 'argues',\n",
       " 'argument',\n",
       " 'argus',\n",
       " 'ari',\n",
       " 'ariaahrary',\n",
       " 'ariabrisard',\n",
       " 'arian',\n",
       " 'ariana',\n",
       " 'arianagrande',\n",
       " 'arianareed',\n",
       " 'arin',\n",
       " 'aris',\n",
       " 'ariz',\n",
       " 'arizona',\n",
       " 'arizonadot',\n",
       " 'arizzo',\n",
       " 'arkan',\n",
       " 'arkansas',\n",
       " 'arlington',\n",
       " 'arm',\n",
       " 'armageddon',\n",
       " 'armed',\n",
       " 'armenians',\n",
       " 'armory',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'armys',\n",
       " 'arnhem',\n",
       " 'arobotlegion',\n",
       " 'around',\n",
       " 'aroundthe',\n",
       " 'arovolturi',\n",
       " 'arranged',\n",
       " 'arreat',\n",
       " 'arrest',\n",
       " 'arrested',\n",
       " 'arrestpastornganga',\n",
       " 'arrests',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'arrogant',\n",
       " 'ars',\n",
       " 'arse',\n",
       " 'arsenal',\n",
       " 'arsenals',\n",
       " 'arson',\n",
       " 'arsonist',\n",
       " 'arsonistmusic',\n",
       " 'arsonists',\n",
       " 'art',\n",
       " 'artbrut',\n",
       " 'artectura',\n",
       " 'arti',\n",
       " 'articals',\n",
       " 'article',\n",
       " 'articles',\n",
       " 'artificial',\n",
       " 'artillery',\n",
       " 'artist',\n",
       " 'artisteoftheweekfact',\n",
       " 'artists',\n",
       " 'artistsunited',\n",
       " 'arts',\n",
       " 'artwork',\n",
       " 'arvindkejriwal',\n",
       " 'arwx',\n",
       " 'ary',\n",
       " 'asae',\n",
       " 'asap',\n",
       " 'asb',\n",
       " 'asbury',\n",
       " 'asburyparkpress',\n",
       " 'ascend',\n",
       " 'aseer',\n",
       " 'asf',\n",
       " 'ash',\n",
       " 'ashayo',\n",
       " 'ashberxo',\n",
       " 'ashdod',\n",
       " 'ashenforest',\n",
       " 'ashes',\n",
       " 'ashesashes',\n",
       " 'ashestoashes',\n",
       " 'ashghebranious',\n",
       " 'ashj',\n",
       " 'ashley',\n",
       " 'ashrafiyah',\n",
       " 'ashtonsos',\n",
       " 'ashville',\n",
       " 'ashwo',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'asianshawtyy',\n",
       " 'asics',\n",
       " 'aside',\n",
       " 'asimtanvir',\n",
       " 'ask',\n",
       " 'askcharley',\n",
       " 'askconnor',\n",
       " 'asked',\n",
       " 'askforalaska',\n",
       " 'askhcz',\n",
       " 'askin',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'asphalt',\n",
       " 'aspiring',\n",
       " 'ass',\n",
       " 'assad',\n",
       " 'assailant',\n",
       " 'assassinkpg',\n",
       " 'assassins',\n",
       " 'assault',\n",
       " 'assembly',\n",
       " 'asses',\n",
       " 'assessment',\n",
       " 'assets',\n",
       " 'asshole',\n",
       " 'assholes',\n",
       " 'assistance',\n",
       " 'assistant',\n",
       " 'assisting',\n",
       " 'assnchat',\n",
       " 'associated',\n",
       " 'association',\n",
       " 'assume',\n",
       " 'assumes',\n",
       " 'assured',\n",
       " 'asswipe',\n",
       " 'asterpuppet',\n",
       " 'astonishing',\n",
       " 'astounding',\n",
       " 'astrakhan',\n",
       " 'astrologian',\n",
       " 'astrology',\n",
       " 'astros',\n",
       " 'astroturfers',\n",
       " 'asukager',\n",
       " 'asylum',\n",
       " 'asymbina',\n",
       " 'atamathon',\n",
       " 'atc',\n",
       " 'atcha',\n",
       " 'atchisonsean',\n",
       " 'atcinema',\n",
       " 'ate',\n",
       " 'atgrannyshouse',\n",
       " 'atheistic',\n",
       " 'athens',\n",
       " 'athlete',\n",
       " 'athletics',\n",
       " 'atk',\n",
       " 'atl',\n",
       " 'atlanta',\n",
       " 'atlantic',\n",
       " 'atlarnxx',\n",
       " 'atlas',\n",
       " 'atlbizchron',\n",
       " 'atleast',\n",
       " 'atlevents',\n",
       " 'atljw',\n",
       " 'atm',\n",
       " 'atmosphere',\n",
       " 'atmospheric',\n",
       " 'atom',\n",
       " 'atombomb',\n",
       " 'atomic',\n",
       " 'atomicbomb',\n",
       " 'att',\n",
       " 'attached',\n",
       " 'attack',\n",
       " 'attackclose',\n",
       " 'attacked',\n",
       " 'attacking',\n",
       " 'attackonstiles',\n",
       " 'attacks',\n",
       " 'attackshare',\n",
       " 'attained',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attend',\n",
       " 'attendance',\n",
       " 'attended',\n",
       " 'attendees',\n",
       " 'attending',\n",
       " 'attention',\n",
       " 'attic',\n",
       " 'attila',\n",
       " 'attitude',\n",
       " 'attjcdemos',\n",
       " 'attraction',\n",
       " 'attractive',\n",
       " 'atv',\n",
       " 'au',\n",
       " 'aubilenon',\n",
       " 'aubrey',\n",
       " 'auburn',\n",
       " 'auc',\n",
       " 'auckland',\n",
       " 'auction',\n",
       " 'auctions',\n",
       " 'audaciousspunk',\n",
       " 'audacityjamesta',\n",
       " 'audi',\n",
       " 'audience',\n",
       " 'audiences',\n",
       " 'audio',\n",
       " 'audit',\n",
       " 'audreyp',\n",
       " 'aug',\n",
       " 'august',\n",
       " 'aul',\n",
       " 'aunt',\n",
       " 'auntiedote',\n",
       " 'aurora',\n",
       " 'aus',\n",
       " 'ausinstarchitect',\n",
       " 'auspol',\n",
       " 'aussie',\n",
       " 'aussies',\n",
       " 'aust',\n",
       " 'austin',\n",
       " 'austinpearcy',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'australians',\n",
       " 'australias',\n",
       " 'austrian',\n",
       " 'auth',\n",
       " 'authentic',\n",
       " 'authenticating',\n",
       " 'author',\n",
       " 'authorities',\n",
       " 'authormike',\n",
       " 'authors',\n",
       " 'autism',\n",
       " 'autismawareness',\n",
       " 'autistic',\n",
       " 'auto',\n",
       " 'autoames',\n",
       " 'autobiography',\n",
       " 'autobody',\n",
       " 'autoinsurance',\n",
       " 'automatic',\n",
       " 'automation',\n",
       " 'autumn',\n",
       " 'autumnwinter',\n",
       " 'auz',\n",
       " 'av',\n",
       " 'ava',\n",
       " 'available',\n",
       " 'avalanche',\n",
       " 'avalanchesgtgthttpstcoxrrlnhelap',\n",
       " 'avbronstein',\n",
       " ...]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armamos la matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7514x21153 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 71063 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dtm = vect.transform(X_train)\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_array = X_train_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaaaallll</th>\n",
       "      <th>aaaaaand</th>\n",
       "      <th>aaarrrgghhh</th>\n",
       "      <th>aaceorg</th>\n",
       "      <th>aal</th>\n",
       "      <th>aampb</th>\n",
       "      <th>aampw</th>\n",
       "      <th>aan</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zotar</th>\n",
       "      <th>zouma</th>\n",
       "      <th>zourryart</th>\n",
       "      <th>zrnf</th>\n",
       "      <th>zss</th>\n",
       "      <th>zumiez</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zxathetis</th>\n",
       "      <th>zzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7509</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7510</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7511</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7512</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7513</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7514 rows × 21153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aa  aaaa  aaaaaaallll  aaaaaand  aaarrrgghhh  aaceorg  aal  aampb  \\\n",
       "0      0     0            0         0            0        0    0      0   \n",
       "1      0     0            0         0            0        0    0      0   \n",
       "2      0     0            0         0            0        0    0      0   \n",
       "3      0     0            0         0            0        0    0      0   \n",
       "4      0     0            0         0            0        0    0      0   \n",
       "...   ..   ...          ...       ...          ...      ...  ...    ...   \n",
       "7509   0     0            0         0            0        0    0      0   \n",
       "7510   0     0            0         0            0        0    0      0   \n",
       "7511   0     0            0         0            0        0    0      0   \n",
       "7512   0     0            0         0            0        0    0      0   \n",
       "7513   0     0            0         0            0        0    0      0   \n",
       "\n",
       "      aampw  aan  ...  zoom  zotar  zouma  zourryart  zrnf  zss  zumiez  \\\n",
       "0         0    0  ...     0      0      0          0     0    0       0   \n",
       "1         0    0  ...     0      0      0          0     0    0       0   \n",
       "2         0    0  ...     0      0      0          0     0    0       0   \n",
       "3         0    0  ...     0      0      0          0     0    0       0   \n",
       "4         0    0  ...     0      0      0          0     0    0       0   \n",
       "...     ...  ...  ...   ...    ...    ...        ...   ...  ...     ...   \n",
       "7509      0    0  ...     0      0      0          0     0    0       0   \n",
       "7510      0    0  ...     0      0      0          0     0    0       0   \n",
       "7511      0    0  ...     0      0      0          0     0    0       0   \n",
       "7512      0    0  ...     0      0      0          0     0    0       0   \n",
       "7513      0    0  ...     0      0      0          0     0    0       0   \n",
       "\n",
       "      zurich  zxathetis  zzzz  \n",
       "0          0          0     0  \n",
       "1          0          0     0  \n",
       "2          0          0     0  \n",
       "3          0          0     0  \n",
       "4          0          0     0  \n",
       "...      ...        ...   ...  \n",
       "7509       0          0     0  \n",
       "7510       0          0     0  \n",
       "7511       0          0     0  \n",
       "7512       0          0     0  \n",
       "7513       0          0     0  \n",
       "\n",
       "[7514 rows x 21153 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_array,columns = vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** OBS: Notemos que la matriz tiene tantas filas como cantidad de tweets y tantas columnas como tokens. En este caso se encontraron 17413 tokens. Podemos notar como la mayría de los elementos de la matriz son cero como mencionamos anteriormente ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenando el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos el clasificador multinomial Naive Bayes para realizar  la clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.62 ms, sys: 3.06 ms, total: 5.68 ms\n",
      "Wall time: 4.99 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probamos el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre el set de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_train = nb.predict(X_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_train,predicciones_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre el set de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<99x21153 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 709 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_test = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8686868686868687"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,predicciones_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando el submit de Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit= pd.read_csv('test.csv',usecols = ['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0                    Just happened a terrible car crash\n",
       "1     Heard about #earthquake is different cities, s...\n",
       "2     there is a forest fire at spot pond, geese are...\n",
       "3              Apocalypse lighting. #Spokane #wildfires\n",
       "4         Typhoon Soudelor kills 28 in China and Taiwan\n",
       "...                                                 ...\n",
       "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...\n",
       "3259  Storm in RI worse than last hurricane. My city...\n",
       "3260  Green Line derailment in Chicago http://t.co/U...\n",
       "3261  MEG issues Hazardous Weather Outlook (HWO) htt...\n",
       "3262  #CityofCalgary has activated its Municipal Eme...\n",
       "\n",
       "[3263 rows x 1 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpiamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['text'] = submit['text'].apply(eliminar_numeros)\n",
    "submit['text'] = submit['text'].apply(eliminar_puntuacion)\n",
    "submit['text'] = submit['text'].apply(minusculas)\n",
    "submit['text'] = submit['text'].apply(eliminar_url)\n",
    "submit['text'] = submit['text'].apply(eliminar_comunes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happened terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heard earthquake different cities stay safe e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>forest fire spot pond geese fleeing across st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apocalypse lighting spokane wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>typhoon soudelor kills china taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>earthquake safety los angeles ûò safety faste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>storm ri worse last hurricane cityampothers h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>green line derailment chicago httptcoutbxlcbiuy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>meg issues hazardous weather outlook hwo http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>cityofcalgary activated municipal emergency p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0                           happened terrible car crash\n",
       "1      heard earthquake different cities stay safe e...\n",
       "2      forest fire spot pond geese fleeing across st...\n",
       "3                 apocalypse lighting spokane wildfires\n",
       "4                   typhoon soudelor kills china taiwan\n",
       "...                                                 ...\n",
       "3258   earthquake safety los angeles ûò safety faste...\n",
       "3259   storm ri worse last hurricane cityampothers h...\n",
       "3260    green line derailment chicago httptcoutbxlcbiuy\n",
       "3261   meg issues hazardous weather outlook hwo http...\n",
       "3262   cityofcalgary activated municipal emergency p...\n",
       "\n",
       "[3263 rows x 1 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predecimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = vect.transform(submit['text'])\n",
    "predicciones_kaggle = nb.predict(texts)\n",
    "submit['target'] = predicciones_kaggle\n",
    "#submit.to_csv('SUBMITS/submission-onehot.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
