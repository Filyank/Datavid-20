{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [75.06 / 95.58] Organización de Datos\n",
    "## Trabajo Práctico 2: Competencia de Machine Learning\n",
    "### Grupo 18: DATAVID-20\n",
    "\n",
    "* 102732 - Bilbao, Manuel\n",
    "* 101933 - Karagoz, Filyan\n",
    "* 98684 - Markarian, Darío\n",
    "* 100901 - Stroia, Lautaro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación general de librerias y set-up de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#!pip3 install tensorflow_text\n",
    "import tensorflow as tf\n",
    "import tensorflow_text\n",
    "import tensorflow_hub as hub \n",
    "\n",
    "\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.max_rows = None #mostrar todas las filas del df\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:20,.2f}'.format # suprimimos la notacion cientifica en los outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up y limpieza de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "#Eliminar numeros de un texto\n",
    "def eliminar_numeros(text):\n",
    "    return re.sub(\"\\d+\", \"\",text)\n",
    "\n",
    "#Eliminar puntuacion\n",
    "def eliminar_puntuacion(text):\n",
    "    return re.sub(r'[^\\w\\s]','',text)\n",
    "\n",
    "#Pasar letras a minusculas\n",
    "def minusculas(text):\n",
    "    return text.lower()\n",
    "\n",
    "#Eliminar caracteres especiales\n",
    "def eliminar_caracteres(text):\n",
    "    return re.sub('[^a-zA-Z0-9 \\n\\.]', '',text)\n",
    "\n",
    "#Eliminar urls\n",
    "def eliminar_url(text):\n",
    "    url_reg = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_reg.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [test,train]:\n",
    "    data['text'] = data['text'].apply(lambda x: eliminar_puntuacion(x))\n",
    "    data['text'] = data['text'].apply(lambda x: minusculas(x))\n",
    "    data['text'] = data['text'].apply(lambda x: eliminar_numeros(x))\n",
    "    data['text'] = data['text'].apply(lambda x: eliminar_caracteres(x))\n",
    "    data['text'] = data['text'].apply(lambda x: remove_stopwords(x))\n",
    "    data['text'] = data['text'].apply(lambda x: eliminar_url(x))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SVM - Classification (hiperparametros default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este algoritmo usa \"kernels\", los que transforman los datos de entrada en un formato especifico: toman el input de baja dimension y lo transforma en datos de una dimension mayor. Esto ayuda a mejorar el accuracy del clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Tokenizacion y Split de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Universal Sentence Encoder\n",
    "encoder = hub.load('https://tfhub.dev/google/universal-sentence-encoder-large/5')\n",
    "\n",
    "#hago reshape de los vectores encodeados y les doy formato unidimensional con el reshape [-1]\n",
    "train_tokens = [tf.reshape(encoder([line]), [-1]).numpy() for line in train.text]\n",
    "test_tokens = [tf.reshape(encoder([line]), [-1]).numpy() for line in test.text]\n",
    "\n",
    "#Divido el set de train en 80% training y 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_tokens, train.target, test_size = 0.2,\n",
    "                                                   random_state = 139)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Generar, entrenar y evaluar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.8168089297439265\n",
      "Precision score 0.8422876949740035\n",
      "Recall score 0.7210682492581603\n",
      "f1_score 0.7769784172661871\n"
     ]
    }
   ],
   "source": [
    "#Generamos un clasificador SVC con un kernel lineal\n",
    "classifier = svm.SVC(kernel='linear', probability=True)\n",
    "\n",
    "#Entrenamos\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "#Predecimos\n",
    "preds = classifier.predict(X_test)\n",
    "print('Accuracy score', accuracy_score(y_test, preds))\n",
    "print('Precision score', sklearn.metrics.precision_score(y_test,preds))\n",
    "print('Recall score', sklearn.metrics.recall_score(y_test, preds))\n",
    "print('f1_score', f1_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Prediccion y submit de kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = classifier.predict(test_tokens) #0.805 KAGGLE\n",
    "submit = pd.DataFrame(test['id'])\n",
    "submit['target'] = test_pred\n",
    "#submit.to_csv('SUBMITS/submission-svm.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SVM - Classification (con RandomizedSearchCV)\n",
    "\n",
    "Con RandomizedSearchCV buscamos los mejores valores para los hiperparametros del SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Tokenizacion y Split de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Universal Sentence Encoder\n",
    "encoder2 = hub.load('https://tfhub.dev/google/universal-sentence-encoder-large/5')\n",
    "\n",
    "#hago reshape de los vectores encodeados y les doy formato unidimensional con el reshape [-1]\n",
    "train_tokens2 = [tf.reshape(encoder2([line]), [-1]).numpy() for line in train.text]\n",
    "test_tokens2 = [tf.reshape(encoder2([line]), [-1]).numpy() for line in test.text]\n",
    "\n",
    "#Divido el set de train en 80% training y 20% test\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(train_tokens2, train.target, test_size = 0.2,\n",
    "                                                   random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Generar, entrenar y evaluar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos un clasificador SVC\n",
    "classifier2 = svm.SVC()\n",
    "\n",
    "#Hiperparametros\n",
    "parameter_space= {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['linear','sigmoid','poly','rbf']}  \n",
    "\n",
    "#RandomizedSearch para hiperparametros\n",
    "random_params = RandomizedSearchCV(classifier2, parameter_space, refit = True)\n",
    "\n",
    "#entrenamiento\n",
    "model = random_params.fit(X_train2, y_train2)\n",
    "\n",
    "#Vemos cuales son los hiperparametros que mejores resultaados dan\n",
    "model.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.8194353250164149\n",
      "Precision score 0.857421875\n",
      "Recall score 0.6848673946957878\n",
      "f1_score 0.761491760624458\n"
     ]
    }
   ],
   "source": [
    "#Predecimos\n",
    "preds = model.predict(X_test2)\n",
    "print('Accuracy score', accuracy_score(y_test2, preds))\n",
    "print('Precision score', sklearn.metrics.precision_score(y_test2,preds))\n",
    "print('Recall score', sklearn.metrics.recall_score(y_test2, preds))\n",
    "print('f1_score', f1_score(y_test2, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Submit Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred2 = model.predict(test_tokens2) #0.8109 en kaggle\n",
    "submit = pd.DataFrame(test['id'])\n",
    "submit['target'] = test_pred2\n",
    "#submit.to_csv('SUBMITS/submission-svm-gridsearch.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SVM con un poquito de feature engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Tokenizacion y split de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train.copy()\n",
    "test_features = test.copy()\n",
    "\n",
    "test_features['keyword'] = test_features['keyword'].fillna('unknown').apply(lambda x: re.sub(r'%20',' ', str(x)))\n",
    "train_features['keyword'] = train_features['keyword'].fillna('unknown').apply(lambda x: re.sub(r'%20',' ', str(x)))\n",
    "\n",
    "for data in [test_features, train_features]:\n",
    "    data['tweet_len'] = data['text'].str.len()\n",
    "    data['qty_strings'] = data['text'].apply(lambda x: len(str(x).split()))\n",
    "    data['len_gt_mean'] = (data['tweet_len'] > data['tweet_len'].mean()).astype(int)\n",
    "    data['has_keyword_notempty'] = (data['keyword'] != 'unknown').astype(int)\n",
    "    data['qty_keywords'] = data['keyword'].apply(lambda x: len(str(x).split()))\n",
    "    data['qty_urls'] = data['text'].apply(lambda x: x.count('http'))\n",
    "    data['has_location_notempty'] = (data['location'] != 'unknown').astype(int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Universal Sentence Encoder\n",
    "encoder3 = hub.load('https://tfhub.dev/google/universal-sentence-encoder-large/5')\n",
    "\n",
    "#hago reshape de los vectores encodeados y les doy formato unidimensional con el reshape [-1]\n",
    "train_tokens3 = [tf.reshape(encoder3([line]), [-1]).numpy() for line in train_features.text]\n",
    "test_tokens3 = [tf.reshape(encoder3([line]), [-1]).numpy() for line in test_features.text]\n",
    "\n",
    "train_tokens3 = pd.DataFrame(train_tokens3)\n",
    "test_tokens3 = pd.DataFrame(test_tokens3)\n",
    "\n",
    "train_tokens3['tweet_len'] = train_features['tweet_len']\n",
    "train_tokens3['qty_strings'] = train_features['qty_strings']\n",
    "train_tokens3['len_gt_mean'] = train_features['len_gt_mean']\n",
    "train_tokens3['has_keyword_notempty'] = train_features['has_keyword_notempty']\n",
    "train_tokens3['qty_keywords'] = train_features['qty_keywords']\n",
    "train_tokens3['qty_urls'] = train_features['qty_urls']\n",
    "train_tokens3['has_location_notempty'] = train_features['has_location_notempty']\n",
    "\n",
    "test_tokens3['tweet_len'] = test_features['tweet_len']\n",
    "test_tokens3['qty_strings'] = test_features['qty_strings']\n",
    "test_tokens3['len_gt_mean'] = test_features['len_gt_mean']\n",
    "test_tokens3['has_keyword_notempty'] = test_features['has_keyword_notempty']\n",
    "test_tokens3['qty_keywords'] = test_features['qty_keywords']\n",
    "test_tokens3['qty_urls'] = test_features['qty_urls']\n",
    "test_tokens3['has_location_notempty'] = test_features['has_location_notempty']\n",
    "        \n",
    "\n",
    "#Divido el set de train en 80% training y 20% test\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(train_tokens3, train_features.target, test_size = 0.2,\n",
    "                                                   random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Generar, entrenar y evaluar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, gamma=0.0001, kernel='linear')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generamos un clasificador SVC \n",
    "classifier3 = svm.SVC(C=0.1, gamma=0.0001,kernel='linear')\n",
    "\n",
    "#Hiperparametros\n",
    "#params = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "#              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "#              'kernel': ['linear','sigmoid','rbf']}  \n",
    "#Entrenamos\n",
    "classifier3.fit(X_train3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.8082731451083388\n",
      "Precision score 0.8003442340791739\n",
      "Recall score 0.7254290171606864\n",
      "f1_score 0.7610474631751228\n"
     ]
    }
   ],
   "source": [
    "#Predecimos\n",
    "preds3 = classifier3.predict(X_test3)\n",
    "print('Accuracy score', accuracy_score(y_test3, preds3))\n",
    "print('Precision score', sklearn.metrics.precision_score(y_test3,preds3))\n",
    "print('Recall score', sklearn.metrics.recall_score(y_test3, preds3))\n",
    "print('f1_score', f1_score(y_test3, preds3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Submit de Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred3 = classifier3.predict(test_tokens3) #0.80324 en kaggle\n",
    "submit = pd.DataFrame(test['id'])\n",
    "submit['target'] = test_pred3\n",
    "#submit.to_csv('SUBMITS/submission-svm-features.csv',index=False)\n",
    "\n",
    "#DIO MENOR SCORE EN KAGGLE QUE USANDO SOLO COLUMNA DE TEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SVM + Keyword + Tuneo de hiperparametros\n",
    "\n",
    "**Features a usar:**keywords.\n",
    "**Tunear hiperparametros con RandomizedSearchCV**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Tokenizacion y split de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train4 = train.copy()\n",
    "test4 = test.copy()\n",
    "test4['keyword'] = test4['keyword'].fillna('unknown').apply(lambda x: re.sub(r'%20',' ', str(x)))\n",
    "train4['keyword'] = train4['keyword'].fillna('unknown').apply(lambda x: re.sub(r'%20',' ', str(x)))\n",
    "\n",
    "train4['combined_text'] = train4['text']+';'+train4['keyword']\n",
    "test4['combined_text'] = test4['text']+';'+test4['keyword']\n",
    "\n",
    "#Universal Sentence Encoder\n",
    "encoder4 = hub.load('https://tfhub.dev/google/universal-sentence-encoder-large/5')\n",
    "\n",
    "#hago reshape de los vectores encodeados y les doy formato unidimensional con el reshape [-1]\n",
    "train_tokens4 = [tf.reshape(encoder4([line]), [-1]).numpy() for line in train4.combined_text]\n",
    "test_tokens4 = [tf.reshape(encoder4([line]), [-1]).numpy() for line in test4.combined_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens4 = pd.DataFrame(train_tokens4)\n",
    "test_tokens4 = pd.DataFrame(test_tokens4)\n",
    "\n",
    "train_tokens4['tweet_len'] = train4['text'].str.len()\n",
    "test_tokens4['tweet_len'] = test4['text'].str.len()\n",
    "#Divido el set de train en 80% training y 20% test\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(train_tokens4, train4.target, test_size = 0.2,\n",
    "                                                   random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] kernel=sigmoid, gamma=1, C=1 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ kernel=sigmoid, gamma=1, C=1, score=0.568, total=  15.0s\n",
      "[CV] kernel=sigmoid, gamma=1, C=1 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   15.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ kernel=sigmoid, gamma=1, C=1, score=0.568, total=  14.5s\n",
      "[CV] kernel=sigmoid, gamma=1, C=1 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   29.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ kernel=sigmoid, gamma=1, C=1, score=0.568, total=  14.6s\n",
      "[CV] kernel=sigmoid, gamma=1, C=1 ....................................\n",
      "[CV] ........ kernel=sigmoid, gamma=1, C=1, score=0.567, total=  14.0s\n",
      "[CV] kernel=sigmoid, gamma=1, C=1 ....................................\n",
      "[CV] ........ kernel=sigmoid, gamma=1, C=1, score=0.568, total=  15.3s\n",
      "[CV] kernel=rbf, gamma=0.0001, C=0.1 .................................\n",
      "[CV] ..... kernel=rbf, gamma=0.0001, C=0.1, score=0.607, total=  15.2s\n",
      "[CV] kernel=rbf, gamma=0.0001, C=0.1 .................................\n",
      "[CV] ..... kernel=rbf, gamma=0.0001, C=0.1, score=0.598, total=  15.3s\n",
      "[CV] kernel=rbf, gamma=0.0001, C=0.1 .................................\n",
      "[CV] ..... kernel=rbf, gamma=0.0001, C=0.1, score=0.605, total=  15.3s\n",
      "[CV] kernel=rbf, gamma=0.0001, C=0.1 .................................\n",
      "[CV] ..... kernel=rbf, gamma=0.0001, C=0.1, score=0.589, total=  15.1s\n",
      "[CV] kernel=rbf, gamma=0.0001, C=0.1 .................................\n",
      "[CV] ..... kernel=rbf, gamma=0.0001, C=0.1, score=0.588, total=  15.1s\n",
      "[CV] kernel=sigmoid, gamma=1, C=1000 .................................\n",
      "[CV] ..... kernel=sigmoid, gamma=1, C=1000, score=0.442, total=   9.0s\n",
      "[CV] kernel=sigmoid, gamma=1, C=1000 .................................\n",
      "[CV] ..... kernel=sigmoid, gamma=1, C=1000, score=0.474, total=   9.0s\n",
      "[CV] kernel=sigmoid, gamma=1, C=1000 .................................\n",
      "[CV] ..... kernel=sigmoid, gamma=1, C=1000, score=0.448, total=   9.2s\n",
      "[CV] kernel=sigmoid, gamma=1, C=1000 .................................\n",
      "[CV] ..... kernel=sigmoid, gamma=1, C=1000, score=0.567, total=  14.1s\n",
      "[CV] kernel=sigmoid, gamma=1, C=1000 .................................\n",
      "[CV] ..... kernel=sigmoid, gamma=1, C=1000, score=0.486, total=   8.9s\n",
      "[CV] kernel=sigmoid, gamma=0.1, C=0.1 ................................\n",
      "[CV] .... kernel=sigmoid, gamma=0.1, C=0.1, score=0.568, total=  14.1s\n",
      "[CV] kernel=sigmoid, gamma=0.1, C=0.1 ................................\n",
      "[CV] .... kernel=sigmoid, gamma=0.1, C=0.1, score=0.568, total=  14.1s\n",
      "[CV] kernel=sigmoid, gamma=0.1, C=0.1 ................................\n",
      "[CV] .... kernel=sigmoid, gamma=0.1, C=0.1, score=0.568, total=  14.3s\n",
      "[CV] kernel=sigmoid, gamma=0.1, C=0.1 ................................\n",
      "[CV] .... kernel=sigmoid, gamma=0.1, C=0.1, score=0.568, total=  13.9s\n",
      "[CV] kernel=sigmoid, gamma=0.1, C=0.1 ................................\n",
      "[CV] .... kernel=sigmoid, gamma=0.1, C=0.1, score=0.568, total=  14.2s\n",
      "[CV] kernel=linear, gamma=0.01, C=100 ................................\n",
      "[CV] .... kernel=linear, gamma=0.01, C=100, score=0.786, total=10.0min\n",
      "[CV] kernel=linear, gamma=0.01, C=100 ................................\n",
      "[CV] .... kernel=linear, gamma=0.01, C=100, score=0.803, total=15.8min\n",
      "[CV] kernel=linear, gamma=0.01, C=100 ................................\n",
      "[CV] .... kernel=linear, gamma=0.01, C=100, score=0.804, total=18.8min\n",
      "[CV] kernel=linear, gamma=0.01, C=100 ................................\n",
      "[CV] .... kernel=linear, gamma=0.01, C=100, score=0.803, total=14.5min\n",
      "[CV] kernel=linear, gamma=0.01, C=100 ................................\n",
      "[CV] .... kernel=linear, gamma=0.01, C=100, score=0.773, total=18.6min\n",
      "[CV] kernel=poly, gamma=0.001, C=1000 ................................\n",
      "[CV] .... kernel=poly, gamma=0.001, C=1000, score=0.785, total=14.1min\n",
      "[CV] kernel=poly, gamma=0.001, C=1000 ................................\n",
      "[CV] .... kernel=poly, gamma=0.001, C=1000, score=0.791, total=20.8min\n",
      "[CV] kernel=poly, gamma=0.001, C=1000 ................................\n",
      "[CV] .... kernel=poly, gamma=0.001, C=1000, score=0.782, total=17.2min\n",
      "[CV] kernel=poly, gamma=0.001, C=1000 ................................\n",
      "[CV] .... kernel=poly, gamma=0.001, C=1000, score=0.782, total=14.8min\n",
      "[CV] kernel=poly, gamma=0.001, C=1000 ................................\n",
      "[CV] .... kernel=poly, gamma=0.001, C=1000, score=0.787, total=30.8min\n",
      "[CV] kernel=rbf, gamma=0.1, C=1 ......................................\n",
      "[CV] .......... kernel=rbf, gamma=0.1, C=1, score=0.774, total=  15.1s\n",
      "[CV] kernel=rbf, gamma=0.1, C=1 ......................................\n",
      "[CV] .......... kernel=rbf, gamma=0.1, C=1, score=0.774, total=  20.8s\n",
      "[CV] kernel=rbf, gamma=0.1, C=1 ......................................\n",
      "[CV] .......... kernel=rbf, gamma=0.1, C=1, score=0.771, total=  23.1s\n",
      "[CV] kernel=rbf, gamma=0.1, C=1 ......................................\n",
      "[CV] .......... kernel=rbf, gamma=0.1, C=1, score=0.782, total=  22.8s\n",
      "[CV] kernel=rbf, gamma=0.1, C=1 ......................................\n",
      "[CV] .......... kernel=rbf, gamma=0.1, C=1, score=0.764, total=  22.9s\n",
      "[CV] kernel=linear, gamma=0.01, C=1 ..................................\n",
      "[CV] ...... kernel=linear, gamma=0.01, C=1, score=0.817, total=  19.2s\n",
      "[CV] kernel=linear, gamma=0.01, C=1 ..................................\n",
      "[CV] ...... kernel=linear, gamma=0.01, C=1, score=0.811, total=  18.5s\n",
      "[CV] kernel=linear, gamma=0.01, C=1 ..................................\n",
      "[CV] ...... kernel=linear, gamma=0.01, C=1, score=0.816, total=  19.7s\n",
      "[CV] kernel=linear, gamma=0.01, C=1 ..................................\n",
      "[CV] ...... kernel=linear, gamma=0.01, C=1, score=0.818, total=  19.8s\n",
      "[CV] kernel=linear, gamma=0.01, C=1 ..................................\n",
      "[CV] ...... kernel=linear, gamma=0.01, C=1, score=0.808, total=  20.3s\n",
      "[CV] kernel=rbf, gamma=0.01, C=0.1 ...................................\n",
      "[CV] ....... kernel=rbf, gamma=0.01, C=0.1, score=0.604, total=  23.5s\n",
      "[CV] kernel=rbf, gamma=0.01, C=0.1 ...................................\n",
      "[CV] ....... kernel=rbf, gamma=0.01, C=0.1, score=0.597, total=  23.1s\n",
      "[CV] kernel=rbf, gamma=0.01, C=0.1 ...................................\n",
      "[CV] ....... kernel=rbf, gamma=0.01, C=0.1, score=0.622, total=  23.5s\n",
      "[CV] kernel=rbf, gamma=0.01, C=0.1 ...................................\n",
      "[CV] ....... kernel=rbf, gamma=0.01, C=0.1, score=0.599, total=  23.4s\n",
      "[CV] kernel=rbf, gamma=0.01, C=0.1 ...................................\n",
      "[CV] ....... kernel=rbf, gamma=0.01, C=0.1, score=0.600, total=  23.3s\n",
      "[CV] kernel=poly, gamma=0.1, C=1000 ..................................\n"
     ]
    }
   ],
   "source": [
    "#Generamos un clasificador SVC\n",
    "classifier4 = svm.SVC()\n",
    "\n",
    "#Hiperparametros\n",
    "parameter_space= {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['linear','sigmoid','poly','rbf']}  \n",
    "\n",
    "#RandomizedSearch para hiperparametros\n",
    "random_params = RandomizedSearchCV(classifier4, parameter_space, refit = True, verbose = 3)\n",
    "\n",
    "#Estuvo mas de 8 horas corriendo y faltando 5 fits tiraba warning de memoria ram no disponible. Viendo\n",
    "#los mensajes de cada score, el mejor fue \"kernel=linear, gamma=0.01, C=1, score=0.818\"\n",
    "#Asi que entreno con ese score a mano.\n",
    "#entrenamiento\n",
    "model4 = random_params.fit(X_train4, y_train4)\n",
    "\n",
    "#Vemos cuales son los hiperparametros que mejores resultaados dan\n",
    "model4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.8023637557452397\n",
      "Precision score 0.8079710144927537\n",
      "Recall score 0.6957878315132605\n",
      "f1_score 0.7476948868398995\n"
     ]
    }
   ],
   "source": [
    "#Predecimos\n",
    "preds4 = model4.predict(X_test4)\n",
    "print('Accuracy score', accuracy_score(y_test4, preds4))\n",
    "print('Precision score', sklearn.metrics.precision_score(y_test4,preds4))\n",
    "print('Recall score', sklearn.metrics.recall_score(y_test4, preds4))\n",
    "print('f1_score', f1_score(y_test4, preds4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy score 0.8023637557452397\n",
    "Precision score 0.8079710144927537\n",
    "Recall score 0.6957878315132605\n",
    "f1_score 0.7476948868398995"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
